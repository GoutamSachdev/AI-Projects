{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Articial Intelligence and Machine Learning - Coursework 1 - 1st diet\n",
    "## Air quality dataset\n",
    "# Student Name: \n",
    "# Student Email:\n",
    "\n",
    "I confirm that the material contained within the submitted coursework is all my own work unless otherwise stated below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and problem definition\n",
    "This assignment uses a dataset of 9358 hourly-averaged answers from five different metal-oxide chemical sensors that are integrated into an air quality chemical multi-sensor system. These sensors were installed at street level in a highly polluted part of a city in Italy, and they collected data between March 2004 and February 2005. The dataset contains ground-truth readings and hourly averages of raw sensor data as integer values for carbon monoxide (CO), nitrogen dioxide (NO2), benzoene, total nitrogen oxides (NOx), and non-methanic hydrocarbons (NMHC). Furthermore, the data takes into consideration concept drifts, sensor drifts, and cross-sensitivities that might affect how well sensor concentration estimating capabilities work.\n",
    "  \n",
    " # 1.1 Talk about Classification or Regression Issues:\n",
    "Regression difficulties make up the majority of the issues described in the jobs. Predicting a continuous numerical number, such as the concentration of carbon monoxide (CO) in mg/m^3, is the aim of a regression problem. The goal of Task 1 is to precisely estimate the CO concentration based on sensor data, time, day of the week, and maybe humidity and temperature. Regression is a useful tool for modeling the connection between input characteristics and the target variable when the target variable is a continuous number.\n",
    "\n",
    "In task 2, an Air Quality Index (AQI) is defined and machine learning is used to forecast it. While AQIs are often categorical indices, they may be defined by aggregating continuous variables (ground-truth)\n",
    "\n",
    "## Task 1 is to predict CO concentration using regression analysis.\n",
    "\n",
    "\n",
    "Problem Statement:\n",
    "The goal is to create a regression model that can reliably predict the concentration of carbon monoxide (CO) in mg/m^3 given the hourly-averaged raw sensor values (particularly, PT08.S1(CO)), day of the week, time, and other parameters like temperature and humidity. A co-located reference certified analyzer's CO(GT) variable serves as the ground truth for this forecast.\n",
    "\n",
    "##  Task 2: Using regression to predict the defined air quality index\n",
    "\n",
    "Problem statement: Integrate ground-truth measurements of several gases to create a personalized Air Quality Index (AQI). Create a regression model with machine learning to forecast the specified AQI from raw sensor data and additional pertinent columns of interest. Refrain from making predictions using the ground-truth columns.\n",
    "\n",
    "These issue statements lay the groundwork for applying machine learning approaches to particular problems pertaining to air quality prediction. The issues' regression character fits nicely with the objective of forecasting continuous numerical values, making it easier to use the right regression models and assessment criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data ingeston\n",
    "\n",
    "## Loading the Dataset:\n",
    "\n",
    "The dataset was loaded into a Pandas DataFrame for easy manipulation and analysis.\n",
    "\n",
    "## Initial Exploration:\n",
    "An initial exploration of the dataset was conducted to understand its structure, features, and contents.\n",
    "\n",
    "## Column Selection:\n",
    "Columns deemed relevant for the tasks were identified based on the analysis requirements.\n",
    "\n",
    "## Handling Missing Values:\n",
    "Placeholder values (-200) were replaced with NaN to accurately represent missing or unknown data.\n",
    "\n",
    "## Date and Time Processing:\n",
    "The 'Date' column was converted to a datetime format, and features like day of the week and hour of the day were derived.\n",
    "Peak and Valley Time Identification:\n",
    "\n",
    "Additional features were created to identify peak and valley hours based on the time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the Data:\n",
      "         Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
      "0  10/03/2004  18:00:00     2.6         1360       150      11.9   \n",
      "1  10/03/2004  19:00:00     2.0         1292       112       9.4   \n",
      "2  10/03/2004  20:00:00     2.2         1402        88       9.0   \n",
      "3  10/03/2004  21:00:00     2.2         1376        80       9.2   \n",
      "4  10/03/2004  22:00:00     1.6         1272        51       6.5   \n",
      "\n",
      "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
      "0           1046      166          1056      113          1692         1268   \n",
      "1            955      103          1174       92          1559          972   \n",
      "2            939      131          1140      114          1555         1074   \n",
      "3            948      172          1092      122          1584         1203   \n",
      "4            836      131          1205      116          1490         1110   \n",
      "\n",
      "   T(C)    RH      AH  Unnamed: 15  Unnamed: 16  \n",
      "0  13.6  48.9  0.7578          NaN          NaN  \n",
      "1  13.3  47.7  0.7255          NaN          NaN  \n",
      "2  11.9  54.0  0.7502          NaN          NaN  \n",
      "3  11.0  60.0  0.7867          NaN          NaN  \n",
      "4  11.2  59.6  0.7888          NaN          NaN  \n",
      "\n",
      "Data Types and Missing Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9357 entries, 0 to 9356\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           9357 non-null   object \n",
      " 1   Time           9357 non-null   object \n",
      " 2   CO(GT)         9357 non-null   float64\n",
      " 3   PT08.S1(CO)    9357 non-null   int64  \n",
      " 4   NMHC(GT)       9357 non-null   int64  \n",
      " 5   C6H6(GT)       9357 non-null   float64\n",
      " 6   PT08.S2(NMHC)  9357 non-null   int64  \n",
      " 7   NOx(GT)        9357 non-null   int64  \n",
      " 8   PT08.S3(NOx)   9357 non-null   int64  \n",
      " 9   NO2(GT)        9357 non-null   int64  \n",
      " 10  PT08.S4(NO2)   9357 non-null   int64  \n",
      " 11  PT08.S5(O3)    9357 non-null   int64  \n",
      " 12  T(C)           9357 non-null   float64\n",
      " 13  RH             9357 non-null   float64\n",
      " 14  AH             9357 non-null   float64\n",
      " 15  Unnamed: 15    0 non-null      float64\n",
      " 16  Unnamed: 16    0 non-null      float64\n",
      "dtypes: float64(7), int64(8), object(2)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "            CO(GT)  PT08.S1(CO)     NMHC(GT)     C6H6(GT)  PT08.S2(NMHC)  \\\n",
      "count  9357.000000  9357.000000  9357.000000  9357.000000    9357.000000   \n",
      "mean    -33.970097  1048.990061  -159.090093     1.865683     894.595276   \n",
      "std      77.458405   329.832710   139.789093    41.380206     342.333252   \n",
      "min    -200.000000  -200.000000  -200.000000  -200.000000    -200.000000   \n",
      "25%       0.600000   921.000000  -200.000000     4.000000     711.000000   \n",
      "50%       1.500000  1053.000000  -200.000000     7.900000     895.000000   \n",
      "75%       2.600000  1221.000000  -200.000000    13.600000    1105.000000   \n",
      "max      11.900000  2040.000000  1189.000000    63.700000    2214.000000   \n",
      "\n",
      "           NOx(GT)  PT08.S3(NOx)      NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
      "count  9357.000000   9357.000000  9357.000000   9357.000000  9357.000000   \n",
      "mean    168.616971    794.990168    58.148873   1391.479641   975.072032   \n",
      "std     257.433866    321.993552   126.940455    467.210125   456.938184   \n",
      "min    -200.000000   -200.000000  -200.000000   -200.000000  -200.000000   \n",
      "25%      50.000000    637.000000    53.000000   1185.000000   700.000000   \n",
      "50%     141.000000    794.000000    96.000000   1446.000000   942.000000   \n",
      "75%     284.000000    960.000000   133.000000   1662.000000  1255.000000   \n",
      "max    1479.000000   2683.000000   340.000000   2775.000000  2523.000000   \n",
      "\n",
      "              T(C)           RH           AH  Unnamed: 15  Unnamed: 16  \n",
      "count  9357.000000  9357.000000  9357.000000          0.0          0.0  \n",
      "mean      9.778305    39.485380    -6.837604          NaN          NaN  \n",
      "std      43.203623    51.216145    38.976670          NaN          NaN  \n",
      "min    -200.000000  -200.000000  -200.000000          NaN          NaN  \n",
      "25%      10.900000    34.100000     0.692300          NaN          NaN  \n",
      "50%      17.200000    48.600000     0.976800          NaN          NaN  \n",
      "75%      24.100000    61.900000     1.296200          NaN          NaN  \n",
      "max      44.600000    88.700000     2.231000          NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "file_path = \"AirQuality.csv\"\n",
    "\n",
    "# Load the data into a Pandas DataFrame\n",
    "air_quality_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"Preview of the Data:\")\n",
    "print(air_quality_data.head())\n",
    "\n",
    "# Display information about the data types and missing values\n",
    "print(\"\\nData Types and Missing Values:\")\n",
    "print(air_quality_data.info())\n",
    "\n",
    "# Display basic statistics for each numerical field\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(air_quality_data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation (common to both tasks)\n",
    "Column Management:\n",
    "\n",
    "Removed irrelevant columns for both tasks.\n",
    "Handling Missing Values:\n",
    "\n",
    "Replaced placeholder values (-200) with NaN.\n",
    "Filled missing values using forward fill.\n",
    "Date and Time Processing:\n",
    "\n",
    "Converted 'Date' to datetime and extracted the day of the week.\n",
    "Created 'HourOfDay' from 'Time' for time-based analysis.\n",
    "Peak and Valley Time Identification:\n",
    "\n",
    "Marked peak hours (8-12, 18-22) and valley hours (2-6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types and Missing Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9357 entries, 0 to 9356\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Date           9357 non-null   object        \n",
      " 1   Time           9357 non-null   datetime64[ns]\n",
      " 2   CO(GT)         9357 non-null   float64       \n",
      " 3   PT08.S1(CO)    9357 non-null   float64       \n",
      " 4   NMHC(GT)       9357 non-null   float64       \n",
      " 5   C6H6(GT)       9357 non-null   float64       \n",
      " 6   PT08.S2(NMHC)  9357 non-null   float64       \n",
      " 7   NOx(GT)        9357 non-null   float64       \n",
      " 8   PT08.S3(NOx)   9357 non-null   float64       \n",
      " 9   NO2(GT)        9357 non-null   float64       \n",
      " 10  PT08.S4(NO2)   9357 non-null   float64       \n",
      " 11  PT08.S5(O3)    9357 non-null   float64       \n",
      " 12  T(C)           9357 non-null   float64       \n",
      " 13  RH             9357 non-null   float64       \n",
      " 14  AH             9357 non-null   float64       \n",
      " 15  DayOfWeek      9357 non-null   object        \n",
      " 16  HourOfDay      9357 non-null   int64         \n",
      " 17  PeakTime       9357 non-null   bool          \n",
      " 18  ValleyTime     9357 non-null   bool          \n",
      "dtypes: bool(2), datetime64[ns](1), float64(13), int64(1), object(2)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "            CO(GT)  PT08.S1(CO)     NMHC(GT)     C6H6(GT)  PT08.S2(NMHC)  \\\n",
      "count  9357.000000  9357.000000  9357.000000  9357.000000    9357.000000   \n",
      "mean      2.083446  1102.730362   270.496740    10.190392     942.548253   \n",
      "std       1.470453   219.588101    73.306853     7.565771     269.581368   \n",
      "min       0.100000   647.000000     7.000000     0.100000     383.000000   \n",
      "25%       1.000000   938.000000   275.000000     4.400000     733.000000   \n",
      "50%       1.700000  1062.000000   275.000000     8.300000     911.000000   \n",
      "75%       2.800000  1237.000000   275.000000    14.000000    1117.000000   \n",
      "max      11.900000  2040.000000  1189.000000    63.700000    2214.000000   \n",
      "\n",
      "           NOx(GT)  PT08.S3(NOx)      NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
      "count  9357.000000   9357.000000  9357.000000   9357.000000  9357.000000   \n",
      "mean    240.731217    832.742225   109.414877   1453.014535  1030.511916   \n",
      "std     206.618453    255.709423    47.221662    347.434084   410.916759   \n",
      "min       2.000000    322.000000     2.000000    551.000000   221.000000   \n",
      "25%      97.000000    655.000000    73.000000   1228.000000   726.000000   \n",
      "50%     174.000000    807.000000   102.000000   1460.000000   964.000000   \n",
      "75%     318.000000    968.000000   137.000000   1677.000000  1287.000000   \n",
      "max    1479.000000   2683.000000   340.000000   2775.000000  2523.000000   \n",
      "\n",
      "              T(C)           RH           AH    HourOfDay  \n",
      "count  9357.000000  9357.000000  9357.000000  9357.000000  \n",
      "mean     18.317356    48.817431     1.017382    11.498557  \n",
      "std       8.821883    17.354326     0.404829     6.923182  \n",
      "min      -1.900000     9.200000     0.184700     0.000000  \n",
      "25%      11.900000    35.400000     0.726200     5.000000  \n",
      "50%      17.600000    48.900000     0.987500    11.000000  \n",
      "75%      24.300000    61.900000     1.306700    18.000000  \n",
      "max      44.600000    88.700000     2.231000    23.000000  \n",
      "0       10/03/2004\n",
      "1       10/03/2004\n",
      "2       10/03/2004\n",
      "3       10/03/2004\n",
      "4       10/03/2004\n",
      "           ...    \n",
      "9352    04/04/2005\n",
      "9353    04/04/2005\n",
      "9354    04/04/2005\n",
      "9355    04/04/2005\n",
      "9356    04/04/2005\n",
      "Name: Date, Length: 9357, dtype: object\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['Unnamed: 15', 'Unnamed: 16']\n",
    "air_quality_data.drop(columns=columns_to_drop, inplace=True)\n",
    "# Replace -200 with NaN in the entire DataFrame\n",
    "air_quality_data.replace(-200, np.nan, inplace=True)\n",
    "# Handle missing values based on your strategy (e.g., mean, median, forward fill, etc.)\n",
    "air_quality_data.fillna(method='ffill', inplace=True)  # Example: forward fill missing values\n",
    "# 4. Create a New Attribute for the Day of the Week\n",
    "# Convert 'Time' to datetime type\n",
    "air_quality_data['Time'] = pd.to_datetime(air_quality_data['Time'])\n",
    "\n",
    "# Create a new attribute for the day of the week\n",
    "air_quality_data['DayOfWeek'] = air_quality_data['Time'].dt.day_name()\n",
    "\n",
    "# Create a new field for the hour of the day\n",
    "air_quality_data['HourOfDay'] = air_quality_data['Time'].dt.hour\n",
    "\n",
    "# 6. Create a New Field for Peak Time\n",
    "peak_hours = ((8 <= air_quality_data['HourOfDay']) & (air_quality_data['HourOfDay'] < 12)) | ((18 <= air_quality_data['HourOfDay']) & (air_quality_data['HourOfDay'] < 22))\n",
    "air_quality_data['PeakTime'] = peak_hours\n",
    "\n",
    "\n",
    "# 6. Create a New Field for Valley Time\n",
    "valley_hours = ((2 <= air_quality_data['Time'].apply(lambda x: x.hour)) & (air_quality_data['Time'].apply(lambda x: x.hour) < 6))\n",
    "air_quality_data['ValleyTime'] = valley_hours\n",
    "print(\"\\nData Types and Missing Values:\")\n",
    "print(air_quality_data.info())\n",
    "print(air_quality_data.describe())\n",
    "print(air_quality_data['Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # TASK 1: CO concentration prediction\n",
    "    Predict the CO concentration (in mg/m3) based on, at least, the PT08.S1(CO) raw sensor readings, day of the week and time. \n",
    "\n",
    "    Maybe temperature and humidity can play a role as well? \n",
    "\n",
    "    Use CO(GT) as the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Further Data preparation (specific for this task)\n",
    "## Data segregation\n",
    "Consider the nature of your air quality variables and the reasons for missingness. Choose an imputation method that aligns with the characteristics of the data. Assess the impact of imputation on your analyses.\n",
    "\n",
    "## Justification for Data Binning:\n",
    "Simplification: Binning simplifies complex continuous data, making it more manageable.\n",
    "\n",
    "Non-Linearity Handling: Useful for capturing non-linear patterns, enhancing model performance.\n",
    "\n",
    "Outlier Mitigation: Helps mitigate the impact of outliers by categorizing values into intervals.\n",
    "\n",
    "Interpretability: Binned data enhances interpretability, aiding communication with non-technical stakeholders.\n",
    "\n",
    "## Potential Application:\n",
    "\n",
    "Air Quality Index (AQI): Binning pollutant concentrations for AQI creation facilitates clear communication of air quality levels.\n",
    "\n",
    "Feature Engineering: Binning features like temperature or humidity improves model understanding.\n",
    "\n",
    "Time-of-Day Patterns: Binning time into categories reveals air quality fluctuations throughout the day.\n",
    "\n",
    "Model Compatibility: Binning suits models like decision trees, enhancing interpretability.##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Columns to keep for Task 1\n",
    "    columns_to_keep = ['PT08.S1(CO)', 'DayOfWeek', 'Time', 'T(C)', 'RH', 'CO(GT)']\n",
    "    air_quality_task1 = df[columns_to_keep].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Check if 'Time' is in datetime format\n",
    "    if 'Time' in air_quality_task1 and pd.api.types.is_datetime64_any_dtype(air_quality_task1['Time']):\n",
    "        # Feature engineering: Extract hour from 'Time'\n",
    "        air_quality_task1['HourOfDay'] = air_quality_task1['Time'].dt.hour\n",
    "\n",
    "        # Automatically fill missing values with forward fill method\n",
    "        air_quality_task1.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        # Encode categorical feature 'DayOfWeek'\n",
    "        air_quality_task1 = pd.get_dummies(air_quality_task1, columns=['DayOfWeek'])\n",
    "\n",
    "        # 'Date' is in datetime format\n",
    "        split_date = pd.to_datetime('2005-01-01')  # Adjust the date accordingly\n",
    "\n",
    "        # Split the data\n",
    "        X_train_task1, X_test_task1, y_train_task1, y_test_task1 = train_test_split(\n",
    "            air_quality_task1.drop('CO(GT)', axis=1),  # Drop the target variable\n",
    "            air_quality_task1['CO(GT)'],\n",
    "            test_size=0.2,\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        return X_train_task1, X_test_task1, y_train_task1, y_test_task1\n",
    "    else:\n",
    "        print(\"Error: 'Time' column not found or is not in datetime format.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "X_train_task1, X_test_task1, y_train_task1, y_test_task1 = preprocess_data(air_quality_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model definition and training\n",
    "Task 1: CO Concentration Prediction\n",
    "\n",
    "Selected relevant features: 'PT08.S1(CO)', 'DayOfWeek', 'HourOfDay', 'T(C)', 'RH'.\n",
    "Handled missing values using forward fill method.\n",
    "Encoded categorical feature 'DayOfWeek' using one-hot encoding.\n",
    "Extracted the hour from the 'Time' column.\n",
    "Split the data into training and testing sets using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 'Time' is a datetime column in X_train_task1\n",
    "X_train_task1['Time_numeric'] = pd.to_numeric(X_train_task1['Time'])\n",
    "\n",
    "# Drop the original datetime column\n",
    "X_train_task1.drop('Time', axis=1, inplace=True)\n",
    "\n",
    "model_task1 = LinearRegression()\n",
    "model_task1.fit(X_train_task1, y_train_task1)\n",
    "\n",
    "# Example of automatic hyperparameter optimization (Grid Search)\n",
    "param_grid_task1 = {'copy_X': [True, False], 'fit_intercept': [True, False]}\n",
    "grid_search_task1 = GridSearchCV(model_task1, param_grid_task1, cv=5)\n",
    "grid_search_task1.fit(X_train_task1, y_train_task1)\n",
    "\n",
    "# Access the best parameters\n",
    "best_params_task1 = grid_search_task1.best_params_\n",
    "optimized_model_task1 = grid_search_task1.best_estimator_\n",
    "\n",
    "# to preprocess  test data similarly \n",
    "X_test_task1['Time_numeric'] = pd.to_numeric(X_test_task1['Time'])\n",
    "X_test_task1.drop('Time', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation\n",
    "## For Task 1,\n",
    "which involves predicting CO concentration, common regression metrics include Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2). These metrics are suitable for evaluating the performance of regression models. Here's a brief outline of why these metrics are appropriate:\n",
    "\n",
    "## Mean Absolute Error (MAE):\n",
    "\n",
    "Definition: MAE represents the average absolute difference between the predicted and actual values.\n",
    "Suitability: MAE is easy to interpret and provides a straightforward measure of the average prediction error. It is less sensitive to outliers compared to MSE.\n",
    "Mean Squared Error (MSE):\n",
    "\n",
    "Definition: MSE measures the average squared difference between predicted and actual values.\n",
    "Suitability: MSE gives higher weight to large errors. It is useful for penalizing larger errors more significantly, which might be important in air quality prediction.\n",
    "## R-squared (R2):\n",
    "\n",
    "Definition: R2 quantifies the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "Suitability: R2 provides an indication of how well the model explains the variability in the data. A higher R2 indicates a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "MAE: 0.6240633812936045\n",
      "MSE: 0.9295436150886374\n",
      "R2: 0.5966987309455807\n",
      "\n",
      "Optimized Model Metrics:\n",
      "MAE: 0.6240633812936045\n",
      "MSE: 0.9295436150886374\n",
      "R2: 0.5966987309455807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Predictions from the baseline model\n",
    "y_pred_baseline_task1 = model_task1.predict(X_test_task1)\n",
    "\n",
    "# Predictions from the optimized model\n",
    "y_pred_optimized_task1 = optimized_model_task1.predict(X_test_task1)\n",
    "\n",
    "# Calculate metrics for the baseline model\n",
    "mae_baseline_task1 = mean_absolute_error(y_test_task1, y_pred_baseline_task1)\n",
    "mse_baseline_task1 = mean_squared_error(y_test_task1, y_pred_baseline_task1)\n",
    "r2_baseline_task1 = r2_score(y_test_task1, y_pred_baseline_task1)\n",
    "\n",
    "# Calculate metrics for the optimized model\n",
    "mae_optimized_task1 = mean_absolute_error(y_test_task1, y_pred_optimized_task1)\n",
    "mse_optimized_task1 = mean_squared_error(y_test_task1, y_pred_optimized_task1)\n",
    "r2_optimized_task1 = r2_score(y_test_task1, y_pred_optimized_task1)\n",
    "\n",
    "# Display the results\n",
    "print(\"Baseline Model Metrics:\")\n",
    "print(f\"MAE: {mae_baseline_task1}\")\n",
    "print(f\"MSE: {mse_baseline_task1}\")\n",
    "print(f\"R2: {r2_baseline_task1}\")\n",
    "print(\"\\nOptimized Model Metrics:\")\n",
    "print(f\"MAE: {mae_optimized_task1}\")\n",
    "print(f\"MSE: {mse_optimized_task1}\")\n",
    "print(f\"R2: {r2_optimized_task1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Air Quality Index creation and prediction\n",
    "Define an Air Quality Index (based on adequate literature) by combining the ground-truth readings of several gases.\n",
    "\n",
    "Then, use ML to predict your Air Quality Index from several raw sensor readings and other columns of interest (obviously without using the ground truth column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Further Data preparation (specific for this task)\n",
    "\n",
    "## Air Quality Index (AQI) Calculation:\n",
    "\n",
    "A new column named 'Personal_AQI' was created by combining ground-truth readings of NO2, CO, and O3. This calculation was performed based on a simple AQI formula.\n",
    "\n",
    "## Column Selection for Task 2:\n",
    "Columns not needed for Task 2, such as 'NO2(GT)', 'CO(GT)', and 'PT08.S5(O3)', were dropped to focus on the relevant features for AQI prediction.\n",
    "\n",
    "## Handling Missing Values:\n",
    "Missing values in the dataset were addressed using a forward-fill method, ensuring that AQI-related features are populated appropriately.\n",
    "\n",
    "## Data Splitting:\n",
    "The dataset was split into features (X_task2) and the target variable (y_task2) for subsequent model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the Data:\n",
      "         Date                Time  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
      "0  10/03/2004 2023-12-10 18:00:00       1360.0     150.0      11.9   \n",
      "1  10/03/2004 2023-12-10 19:00:00       1292.0     112.0       9.4   \n",
      "2  10/03/2004 2023-12-10 20:00:00       1402.0      88.0       9.0   \n",
      "3  10/03/2004 2023-12-10 21:00:00       1376.0      80.0       9.2   \n",
      "4  10/03/2004 2023-12-10 22:00:00       1272.0      51.0       6.5   \n",
      "\n",
      "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  PT08.S4(NO2)  T(C)    RH      AH  \\\n",
      "0         1046.0    166.0        1056.0        1692.0  13.6  48.9  0.7578   \n",
      "1          955.0    103.0        1174.0        1559.0  13.3  47.7  0.7255   \n",
      "2          939.0    131.0        1140.0        1555.0  11.9  54.0  0.7502   \n",
      "3          948.0    172.0        1092.0        1584.0  11.0  60.0  0.7867   \n",
      "4          836.0    131.0        1205.0        1490.0  11.2  59.6  0.7888   \n",
      "\n",
      "  DayOfWeek  HourOfDay  PeakTime  ValleyTime  Personal_AQI  \n",
      "0    Sunday         18      True       False        1383.6  \n",
      "1    Sunday         19      True       False        1066.0  \n",
      "2    Sunday         20      True       False        1190.2  \n",
      "3    Sunday         21      True       False        1327.2  \n",
      "4    Sunday         22     False       False        1227.6  \n",
      "\n",
      "Data Types and Missing Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9357 entries, 0 to 9356\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Date           9357 non-null   object        \n",
      " 1   Time           9357 non-null   datetime64[ns]\n",
      " 2   PT08.S1(CO)    9357 non-null   float64       \n",
      " 3   NMHC(GT)       9357 non-null   float64       \n",
      " 4   C6H6(GT)       9357 non-null   float64       \n",
      " 5   PT08.S2(NMHC)  9357 non-null   float64       \n",
      " 6   NOx(GT)        9357 non-null   float64       \n",
      " 7   PT08.S3(NOx)   9357 non-null   float64       \n",
      " 8   PT08.S4(NO2)   9357 non-null   float64       \n",
      " 9   T(C)           9357 non-null   float64       \n",
      " 10  RH             9357 non-null   float64       \n",
      " 11  AH             9357 non-null   float64       \n",
      " 12  DayOfWeek      9357 non-null   object        \n",
      " 13  HourOfDay      9357 non-null   int64         \n",
      " 14  PeakTime       9357 non-null   bool          \n",
      " 15  ValleyTime     9357 non-null   bool          \n",
      " 16  Personal_AQI   9357 non-null   float64       \n",
      "dtypes: bool(2), datetime64[ns](1), float64(11), int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "       PT08.S1(CO)     NMHC(GT)     C6H6(GT)  PT08.S2(NMHC)      NOx(GT)  \\\n",
      "count  9357.000000  9357.000000  9357.000000    9357.000000  9357.000000   \n",
      "mean   1102.730362   270.496740    10.190392     942.548253   240.731217   \n",
      "std     219.588101    73.306853     7.565771     269.581368   206.618453   \n",
      "min     647.000000     7.000000     0.100000     383.000000     2.000000   \n",
      "25%     938.000000   275.000000     4.400000     733.000000    97.000000   \n",
      "50%    1062.000000   275.000000     8.300000     911.000000   174.000000   \n",
      "75%    1237.000000   275.000000    14.000000    1117.000000   318.000000   \n",
      "max    2040.000000  1189.000000    63.700000    2214.000000  1479.000000   \n",
      "\n",
      "       PT08.S3(NOx)  PT08.S4(NO2)         T(C)           RH           AH  \\\n",
      "count   9357.000000   9357.000000  9357.000000  9357.000000  9357.000000   \n",
      "mean     832.742225   1453.014535    18.317356    48.817431     1.017382   \n",
      "std      255.709423    347.434084     8.821883    17.354326     0.404829   \n",
      "min      322.000000    551.000000    -1.900000     9.200000     0.184700   \n",
      "25%      655.000000   1228.000000    11.900000    35.400000     0.726200   \n",
      "50%      807.000000   1460.000000    17.600000    48.900000     0.987500   \n",
      "75%      968.000000   1677.000000    24.300000    61.900000     1.306700   \n",
      "max     2683.000000   2775.000000    44.600000    88.700000     2.231000   \n",
      "\n",
      "         HourOfDay  Personal_AQI  \n",
      "count  9357.000000   9357.000000  \n",
      "mean     11.498557   1142.010238  \n",
      "std       6.923182    443.464489  \n",
      "min       0.000000    248.200000  \n",
      "25%       5.000000    814.100000  \n",
      "50%      11.000000   1069.600000  \n",
      "75%      18.000000   1421.900000  \n",
      "max      23.000000   2801.900000  \n"
     ]
    }
   ],
   "source": [
    "# Example combining NO2, CO, and O3 for a simple AQI calculation (modify as needed)\n",
    "air_quality_data['Personal_AQI'] = air_quality_data['NO2(GT)'] + air_quality_data['CO(GT)'] + air_quality_data['PT08.S5(O3)']\n",
    "# Drop columns not needed for Task 2\n",
    "columns_to_drop_task2 = ['NO2(GT)', 'CO(GT)', 'PT08.S5(O3)']  # Modify based on your defined AQI components\n",
    "air_quality_data_task2 = air_quality_data.drop(columns=columns_to_drop_task2)\n",
    "# Handle missing values based on your strategy (e.g., mean, median, forward fill, etc.)\n",
    "air_quality_data_task2.fillna(method='ffill', inplace=True)  # Example: forward fill missing values\n",
    "X_task2 = air_quality_data_task2.drop(columns=['Personal_AQI'])\n",
    "y_task2 = air_quality_data_task2['Personal_AQI']\n",
    "X_train_task2, X_test_task2, y_train_task2, y_test_task2 = train_test_split(X_task2, y_task2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"Preview of the Data:\")\n",
    "print(air_quality_data_task2.head())\n",
    "\n",
    "# Display information about the data types and missing values\n",
    "print(\"\\nData Types and Missing Values:\")\n",
    "print(air_quality_data_task2.info())\n",
    "\n",
    "# Display basic statistics for each numerical field\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(air_quality_data_task2.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model definition and training\n",
    "Regression Model Selection:\n",
    "\n",
    "Random Forest Regression is the model.\n",
    "Justification: Because Random Forest Regression can handle intricate interactions and identify non-linear patterns, it was selected. It works well for forecasting composite indices, such as the Air Quality Index.\n",
    "\n",
    "Baseline Model Application:\n",
    "Fit the baseline Random Forest Regression model on the data.\n",
    "Hyperparameter Optimization:\n",
    "Utilize automatic hyperparameter optimization, such as Randomized Search, to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "#  'Time' is a datetime column in X_train_task2\n",
    "X_train_task2['Time_numeric'] = pd.to_numeric(X_train_task2['Time'])\n",
    "\n",
    "# Drop the original datetime column\n",
    "X_train_task2.drop('Time', axis=1, inplace=True)\n",
    "# Convert 'Date' to datetime format\n",
    "X_train_task2['Date'] = pd.to_datetime(X_train_task2['Date'], dayfirst=True)\n",
    "\n",
    "# Extract relevant date features\n",
    "X_train_task2['Day'] = X_train_task2['Date'].dt.day\n",
    "X_train_task2['Month'] = X_train_task2['Date'].dt.month\n",
    "X_train_task2['Year'] = X_train_task2['Date'].dt.year\n",
    "\n",
    "# Drop the original 'Date' column\n",
    "X_train_task2.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encode the 'DayOfWeek' column\n",
    "X_train_task2 = pd.get_dummies(X_train_task2, columns=['DayOfWeek'])\n",
    "\n",
    "# Convert 'Time' to numeric in X_test_task2\n",
    "X_test_task2['Time_numeric'] = pd.to_numeric(X_test_task2['Time'])\n",
    "\n",
    "# Drop the original datetime column in X_test_task2\n",
    "X_test_task2.drop('Time', axis=1, inplace=True)\n",
    "\n",
    "# Convert 'Date' to datetime format in X_test_task2\n",
    "X_test_task2['Date'] = pd.to_datetime(X_test_task2['Date'], dayfirst=True)\n",
    "\n",
    "# Extract relevant date features in X_test_task2\n",
    "X_test_task2['Day'] = X_test_task2['Date'].dt.day\n",
    "X_test_task2['Month'] = X_test_task2['Date'].dt.month\n",
    "X_test_task2['Year'] = X_test_task2['Date'].dt.year\n",
    "\n",
    "# Drop the original 'Date' column in X_test_task2\n",
    "X_test_task2.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encode the 'DayOfWeek' column in X_test_task2\n",
    "X_test_task2 = pd.get_dummies(X_test_task2, columns=['DayOfWeek'])\n",
    "\n",
    "\n",
    "model_task2 = RandomForestRegressor()\n",
    "model_task2.fit(X_train_task2, y_train_task2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation\n",
    "Your text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "MAE: 65.59472329059828\n",
      "MSE: 8291.210890362176\n",
      "R2: 0.9580545288495499\n",
      "\n",
      "Optimized Model Metrics:\n",
      "MAE: 66.56750146968066\n",
      "MSE: 8612.5104823307\n",
      "R2: 0.9564290650971765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of automatic hyperparameter optimization (Randomized Search)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist_task2 = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search_task2 = RandomizedSearchCV(model_task2, param_dist_task2, n_iter=10, cv=5)\n",
    "random_search_task2.fit(X_train_task2, y_train_task2)\n",
    "\n",
    "# Access the best parameters\n",
    "best_params_task2 = random_search_task2.best_params_\n",
    "optimized_model_task2 = random_search_task2.best_estimator_\n",
    "\n",
    "\n",
    "# Baseline model evaluation\n",
    "y_pred_baseline = model_task2.predict(X_test_task2)\n",
    "mae_baseline = mean_absolute_error(y_test_task2, y_pred_baseline)\n",
    "mse_baseline = mean_squared_error(y_test_task2, y_pred_baseline)\n",
    "r2_baseline = r2_score(y_test_task2, y_pred_baseline)\n",
    "\n",
    "# Optimized model evaluation\n",
    "y_pred_optimized = optimized_model_task2.predict(X_test_task2)\n",
    "mae_optimized = mean_absolute_error(y_test_task2, y_pred_optimized)\n",
    "mse_optimized = mean_squared_error(y_test_task2, y_pred_optimized)\n",
    "r2_optimized = r2_score(y_test_task2, y_pred_optimized)\n",
    "\n",
    "\n",
    "# Print or use these metrics for further analysis\n",
    "print(\"Baseline Model Metrics:\")\n",
    "print(f\"MAE: {mae_baseline}\")\n",
    "print(f\"MSE: {mse_baseline}\")\n",
    "print(f\"R2: {r2_baseline}\")\n",
    "\n",
    "\n",
    "print(\"\\nOptimized Model Metrics:\")\n",
    "print(f\"MAE: {mae_optimized}\")\n",
    "print(f\"MSE: {mse_optimized}\")\n",
    "print(f\"R2: {r2_optimized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusions\n",
    "# Task 1 Conclusion and Interpretation:\n",
    "\n",
    "#Baseline Model:\n",
    "Mean Absolute Error (MAE): 0.624\n",
    "Mean Squared Error (MSE): 0.930\n",
    "R-squared (R2): 0.597\n",
    "#Optimized Model:\n",
    "MAE: 0.624\n",
    "MSE: 0.930\n",
    "R2: 0.597\n",
    "\n",
    "# Interpretation:\n",
    "\n",
    "The baseline and optimized models perform similarly, suggesting that the default parameters are effective for this regression task.\n",
    "R2 value of approximately 0.60 indicates that the model explains 60% of the variance in the target variable, which is reasonable but leaves room for improvement.\n",
    "\n",
    "# Suggestions for Improvement:\n",
    "\n",
    "Explore more advanced regression models to see if they can capture complex patterns in the data.\n",
    "Conduct further feature engineering to identify additional relevant features.\n",
    "Fine-tune hyperparameters more precisely.\n",
    "\n",
    "# Task 2 Conclusion and Interpretation:\n",
    "Baseline Model:\n",
    "MAE: 65.595\n",
    "MSE: 8291.211\n",
    "R2: 0.958\n",
    "Optimized Model:\n",
    "MAE: 66.568\n",
    "MSE: 8612.510\n",
    "R2: 0.956\n",
    "\n",
    "# Interpretation:\n",
    "The baseline and optimized models are close in performance, indicating that the default parameters already produce strong results.\n",
    "R2 value of approximately 0.96 indicates that the model explains 96% of the variance in the target variable, suggesting a high level of accuracy.\n",
    "\n",
    "# Suggestions for Improvement:\n",
    "Investigate potential outliers or anomalies in the data that could affect model performance.\n",
    "Consider more advanced models or ensemble methods for further improvement.\n",
    "Evaluate the impact of additional features on the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "This cell goes to the very bottom of your submitted notebok.\n",
    "You are requried to link the sources and web-links that you have used for various parts of this coursework. \n",
    "\n",
    "Write them sources used in the following format similar to the first examle in the sources list below :\n",
    "\n",
    "    - what you have used them for : web-link\n",
    "\n",
    "Sources:\n",
    "\n",
    "- Implement a recurrent neural network : https://peterroelants.github.io/posts/rnn-implementation-part01/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f4fa1dff685cf8b0e8f68ac358400f6497cf659b705a84b1e00c6e6dfedb2d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
